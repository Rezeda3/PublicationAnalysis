{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2YTUYMHMp8h"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def normalize_issn(issn):\n",
        "    \"\"\"Нормализация ISSN: удаление дефисов и приведение к верхнему регистру\"\"\"\n",
        "    return issn.replace('-', '').upper() if issn else None\n",
        "\n",
        "# Конфигурация\n",
        "SCIMAGO_FILE = \"/content/scimagojr_2022.csv\"\n",
        "MAX_ARTICLES = 3000\n",
        "PER_PAGE = 50\n",
        "API_EMAIL = \"SabirovaRA3@ieml.ru\"\n",
        "\n",
        "# 1. Загрузка и подготовка данных Scimago\n",
        "print(\"Загрузка данных Scimago...\")\n",
        "try:\n",
        "    scimago = pd.read_csv(\n",
        "        SCIMAGO_FILE,\n",
        "        sep=';',\n",
        "        encoding='latin1',\n",
        "        usecols=['Issn', 'SJR Best Quartile']\n",
        "    ).rename(columns={'SJR Best Quartile': 'quartile'})\n",
        "\n",
        "    # Создаем словарь ISSN -> Quartile с нормализацией\n",
        "    issn_quartile = {}\n",
        "    for idx, row in scimago.dropna(subset=['Issn']).iterrows():\n",
        "        for issn in str(row['Issn']).split(', '):\n",
        "            normalized_issn = normalize_issn(issn.strip())\n",
        "            if normalized_issn and len(normalized_issn) == 8:\n",
        "                issn_quartile[normalized_issn] = row['quartile']\n",
        "\n",
        "    print(f\"Загружено {len(issn_quartile)} уникальных ISSN из Scimago\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка загрузки файла Scimago: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# 2. Сбор данных из OpenAlex\n",
        "print(\"\\nСбор данных из OpenAlex...\")\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": f\"Research Project ({API_EMAIL})\",\n",
        "    \"From\": API_EMAIL\n",
        "}\n",
        "\n",
        "params = {\n",
        "    \"filter\": \"publication_year:2014-2024,has_doi:true\",\n",
        "    \"select\": \"id,authorships,publication_year,cited_by_count,grants,open_access,primary_location\",\n",
        "    \"per-page\": PER_PAGE,\n",
        "    \"cursor\": \"*\"\n",
        "}\n",
        "\n",
        "data = []\n",
        "attempts = 0\n",
        "progress = tqdm(total=MAX_ARTICLES, desc=\"Сбор статей\")\n",
        "\n",
        "while len(data) < MAX_ARTICLES and attempts < 5:\n",
        "    try:\n",
        "        response = requests.get(\"https://api.openalex.org/works\", headers=headers, params=params, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        results = response.json().get('results', [])\n",
        "        if not results:\n",
        "            print(\"Нет данных в ответе\")\n",
        "            break\n",
        "\n",
        "        for work in results:\n",
        "            try:\n",
        "                # Извлечение основных данных\n",
        "                work_id = work['id'].split('/')[-1]\n",
        "                authorships = work.get('authorships', [])\n",
        "\n",
        "                # Извлечение ID авторов\n",
        "                author_ids = []\n",
        "                for authorship in authorships:\n",
        "                    author = authorship.get('author', {})\n",
        "                    if author.get('id'):\n",
        "                        author_id = author['id'].split('/')[-1]\n",
        "                        author_ids.append(author_id)\n",
        "\n",
        "                if not author_ids:  # Пропускаем публикации без авторов\n",
        "                    continue\n",
        "\n",
        "                # Обработка журнала\n",
        "                primary_location = work.get('primary_location', {})\n",
        "                source = primary_location.get('source', {})\n",
        "                issn_list = source.get('issn', [])\n",
        "\n",
        "                # Поиск квартиля\n",
        "                quartile = None\n",
        "                for issn in issn_list:\n",
        "                    normalized_issn = normalize_issn(issn)\n",
        "                    quartile = issn_quartile.get(normalized_issn)\n",
        "                    if quartile:\n",
        "                        break\n",
        "\n",
        "                if not quartile or quartile not in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
        "                    continue  # Пропускаем публикации без квартиля\n",
        "\n",
        "                # Формирование записи\n",
        "                entry = {\n",
        "                    \"work_id\": work_id,\n",
        "                    \"year\": work.get('publication_year'),\n",
        "                    \"num_authors\": len(author_ids),\n",
        "                    \"author_ids\": \",\".join(author_ids),\n",
        "                    \"citations\": work.get('cited_by_count', 0),\n",
        "                    \"is_oa\": work.get('open_access', {}).get('is_oa', False),\n",
        "                    \"has_grant\": bool(work.get('grants')),\n",
        "                    \"issn\": normalized_issn,\n",
        "                    \"quartile\": quartile,\n",
        "                    \"journal_name\": source.get('display_name', 'Unknown')\n",
        "                }\n",
        "\n",
        "                data.append(entry)\n",
        "                progress.update(1)\n",
        "\n",
        "                if len(data) >= MAX_ARTICLES:\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\nОшибка обработки статьи: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if 'next_cursor' in response.json().get('meta', {}):\n",
        "            params['cursor'] = response.json()['meta']['next_cursor']\n",
        "            time.sleep(1)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nОшибка запроса: {str(e)}\")\n",
        "        attempts += 1\n",
        "        time.sleep(10)\n",
        "\n",
        "progress.close()\n",
        "\n",
        "# 3. Сохранение результатов\n",
        "if data:\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(f\"\\nСохранено {len(df)} записей. Пример данных:\")\n",
        "    print(df[['work_id', 'author_ids', 'quartile', 'citations']].head())\n",
        "\n",
        "    print(\"\\nРаспределение квартилей:\")\n",
        "    print(df['quartile'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
        "\n",
        "    # Сохранение основной таблицы\n",
        "    df.to_csv('publications_with_authors.csv', index=False)\n",
        "\n",
        "    # Создание таблицы связей автор-публикация\n",
        "    author_relations = []\n",
        "    for _, row in df.iterrows():\n",
        "        for author_id in row['author_ids'].split(','):\n",
        "            author_relations.append({\n",
        "                \"work_id\": row['work_id'],\n",
        "                \"author_id\": author_id,\n",
        "                \"quartile\": row['quartile']\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(author_relations).to_csv('author_publication_mapping.csv', index=False)\n",
        "    print(\"\\nСоздана таблица связей автор-публикация (author_publication_mapping.csv)\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nНе удалось собрать данные\")\n",
        "\n",
        "# 4. Валидация данных\n",
        "if not df.empty:\n",
        "    print(\"\\nПроверка данных:\")\n",
        "    print(f\"Всего статей: {len(df)}\")\n",
        "    print(f\"Уникальных авторов: {pd.DataFrame(author_relations)['author_id'].nunique()}\")\n",
        "    print(f\"Средняя цитируемость: {df['citations'].mean():.1f}\")"
      ]
    }
  ]
}